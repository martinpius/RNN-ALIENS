{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to sequence model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSNMvAxES+JlhNIXGcl//p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/RNN-ALIENS/blob/main/Sequence_to_sequence_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "KgovuPAxDL3w",
        "outputId": "8a357677-b227-4ad9-b678-fda9069cade7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import tensorflow as tf\n",
        "  print(f\"You are using Colab with tensorflow version {tf.__version__}\")\n",
        "except Exception as e:\n",
        "  COLAB = False\n",
        "  print(f\"{type(e)}: {e}\\n....Please Load Your Drive....\")\n",
        "\n",
        "def time_fmt(x):\n",
        "  h = int(x / (60 * 60))\n",
        "  m = int(x % (60 * 60) / 60)\n",
        "  s = int(x % 60)\n",
        "  return f\"{h}: {m:>03}: {s:>05.2f}\"\n",
        "\n",
        "time_fmt(240.892)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "You are using Colab with tensorflow version 2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0: 004: 00.00'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMwrOKsREtDn"
      },
      "source": [
        "import time, io, os, re, unicodedata\n",
        "import matplotlib as mlp\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.ticker as ticker\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbZGLDLnFgwR"
      },
      "source": [
        "#Lets build an encoder-decoder network for machine translation"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDu5C5pfFtKG"
      },
      "source": [
        "#Importing and preprocessing the data\n",
        "#We will train a machine to translate spanish language to english\n",
        "#It is a simple MT with attention mechanism to learn variable/words contribution"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utqRIxdjF5vr"
      },
      "source": [
        "folder_path = tf.keras.utils.get_file(fname = \"spa-eng.zip\", origin = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "                                      extract = True)\n",
        "file_path = os.path.dirname(folder_path) + \"/spa-eng/spa.txt\""
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Yiq0qiHyNH"
      },
      "source": [
        "#Change the unicode data format into ascii format:\n",
        "def ascii_fmt(t):\n",
        "  return \"\".join(k for k in unicodedata.normalize('NFD',t) if unicodedata.category(k) != 'Mn')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR7BVnjGIrPg"
      },
      "source": [
        "def preprocess_text(t):\n",
        "  '''We do some cleaning and marking the start and the end of each sentence'''\n",
        "  t = ascii_fmt(t.lower().strip()) #Convert to lower cases and strip the white spaces\n",
        "  t = re.sub(r\"([?,!.多])\", r\" \\1 \", t)\n",
        "  t = re.sub(r'[\" \"]+', \" \", t)\n",
        "  t = re.sub(r'[^a-zA-Z?多,.!]+',\" \", t) # For each sentence we replace the everthing else except the one listed with a white space\n",
        "  t = t.strip() #Strip the white spaces\n",
        "  t = '<start>' + t + '<end>' #Marking the start and the end of each sentence with start, end\n",
        "  return t"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHWwHWiEI_Pz"
      },
      "source": [
        "#Testing the above function if it works as intended:\n",
        "en_verse = u\"May I borrow this book?\"\n",
        "sp_verse = u\"多Puedo tomar prestado este libro?\""
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O80oUj8ZJOJh"
      },
      "source": [
        "en_out = preprocess_text(en_verse)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oda7vrpQJV3T"
      },
      "source": [
        "sp_out = preprocess_text(sp_verse)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu2ja5tPJaZs",
        "outputId": "2f255bf4-a845-4292-f6c2-cb201fb31506"
      },
      "source": [
        "print(en_out)\n",
        "print()\n",
        "print(sp_out)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>may i borrow this book ?<end>\n",
            "\n",
            "<start>多 puedo tomar prestado este libro ?<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqif5h7WJg0I"
      },
      "source": [
        "#Create sentences pairs for english-spanish side by side"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7v5s_DjJyAo"
      },
      "source": [
        "def data_creator(path, sample_size):\n",
        "  lines = io.open(path, encoding = 'UTF-8').read().strip().split(\"\\n\")\n",
        "  words_pair = [[preprocess_text(t) for t in line.split(\"\\t\")] for line in lines[:sample_size]]\n",
        "  return zip(*words_pair)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--01oNVVJ2uk"
      },
      "source": [
        "#Applying the function\n",
        "sample_size = 50000"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSiMh7VHKQgw"
      },
      "source": [
        "#Load the sample of size 50000\n",
        "eng_text, spa_text = data_creator(file_path,sample_size )"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGKQ1-rxKqx1",
        "outputId": "81d5b400-40cb-4f64-9ba4-35e5edd77924"
      },
      "source": [
        "print(f\"English text is : {eng_text[-1]}\")\n",
        "print()\n",
        "print(f\"Spanish text is: {spa_text[-1]}\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English text is : <start>the people are so friendly .<end>\n",
            "\n",
            "Spanish text is: <start>la gente es muy amable .<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAo94cJhK9-m"
      },
      "source": [
        "#Tokenize and padding the data to the right"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAziKOkpMiu-"
      },
      "source": [
        "def ln_tokenization(text):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters = '')\n",
        "  tokenizer.fit_on_texts(text)\n",
        "  tensor = tokenizer.texts_to_sequences(text)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post')\n",
        "  return tensor, tokenizer"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTIrIFhRN5-e"
      },
      "source": [
        "#Load the cleaned and prepared dataset for training our MT-model"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV1YtRAxODXU"
      },
      "source": [
        "def load_clean_data(path, sample_size = None):\n",
        "  target_lang, input_lang = data_creator(file_path, sample_size)\n",
        "  input_tensor, input_tokenizer = ln_tokenization(input_lang)\n",
        "  target_tensor, target_tokenizer = ln_tokenization(target_lang)\n",
        "  return input_tensor, target_tensor, input_tokenizer, target_tokenizer"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZD-McH6PQPY"
      },
      "source": [
        "sample_size = 50000\n",
        "input_tensor, target_tensor, input_lang, target_lang = load_clean_data(file_path, sample_size)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k_Ygw_tPs71",
        "outputId": "fc69d4f5-6079-412a-b6d8-5b1018da5cf5"
      },
      "source": [
        "print(f\"Max_len_input: {input_tensor.shape[1]}, Max_len_output: {target_tensor.shape[1]}\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max_len_input: 14, Max_len_output: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvMtRFsYRCoX"
      },
      "source": [
        "#Split the data for training and testing \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmYqwpZARd_D"
      },
      "source": [
        "x_train, x_test, y_train,y_test = train_test_split(input_tensor, target_tensor, test_size = 0.2)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJO7IR7SAzp",
        "outputId": "cb4bf1a2-1036-4c6d-d555-9c5a7e26a58b"
      },
      "source": [
        "print(f\"x_train_shape: {x_train.shape}, y_train_shape: {y_train.shape}\\nx_test_shape: {x_test.shape}, y_test_shape: {y_test.shape}\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train_shape: (40000, 14), y_train_shape: (40000, 10)\n",
            "x_test_shape: (10000, 14), y_test_shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-dBHEP3S5vv"
      },
      "source": [
        "#Map every word in a text to an index (number)\n",
        "def create_index(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t != 0:\n",
        "      print(\"%d---->%s\" %(t, lang.index_word[t]))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQpwCdsgTTqB",
        "outputId": "db928a01-0cc2-4fa8-ae15-5c4fea9ff172"
      },
      "source": [
        "#Testing the map function\n",
        "print('Input language, index-word mapping')\n",
        "create_index(input_lang, x_train[10])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input language, index-word mapping\n",
            "122----><start>solo\n",
            "92---->era\n",
            "2278---->curiosidad\n",
            "1---->.<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98i8givrUBj4",
        "outputId": "21fc51a7-bd6b-41d4-c536-1b245241777c"
      },
      "source": [
        "print(\"output language, index-word\")\n",
        "create_index(target_lang, y_train[10])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output language, index-word\n",
            "2----><start>i\n",
            "19---->was\n",
            "100---->just\n",
            "1310---->curious\n",
            "1---->.<end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2COumFQzUdD5"
      },
      "source": [
        "#Creating a tensorflow data type for easy training"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAzfHCGyU9_1"
      },
      "source": [
        "batch_size = 64\n",
        "BUFFER = len(x_train)\n",
        "step_per_epoch = BUFFER // batch_size\n",
        "step_per_epoch_eval = len(x_test)//batch_size\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "input_voc_size = len(input_lang.word_index) + 1\n",
        "output_voc_size = len(target_lang.word_index) + 1\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKz-5pBfWWRc"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER)\n",
        "train_data = train_data.batch(batch_size, drop_remainder = True)\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(BUFFER)\n",
        "test_data = test_data.batch(batch_size, drop_remainder = True)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg8TciqVXScR"
      },
      "source": [
        "#The above datasets are ready for training:\n",
        "#We employ model subclassing to build both encoder and decoder network\n",
        "#We the use layer subclassing to construct an attention mechanism\n",
        "#In this project we will employ additive attention (Bhanadau's attention) with 3 parameters to be learnt"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAFGMWTTG8eF"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, enc_units, voc_size, batch_size, embedding_dim, name = 'encoder', **kwargs):\n",
        "    super(Encoder, self).__init__(name = name, **kwargs)\n",
        "    self.enc_units = enc_units\n",
        "    self.batch_size = batch_size\n",
        "    self.enc_embedding = tf.keras.layers.Embedding(input_dim = voc_size, output_dim = embedding_dim, name = 'encoder_embd')\n",
        "    self.enc_gru = tf.keras.layers.GRU(units = self.enc_units, kernel_initializer = 'glorot_uniform',\n",
        "                                       return_state = True, return_sequences = True,\n",
        "                                       recurrent_dropout = 0.5, dropout = 0.5,\n",
        "                                       name = 'encoder_gru')\n",
        "  \n",
        "  def call(self, inputs, hidden):\n",
        "    inputs = self.enc_embedding(inputs)\n",
        "    enc_out, enc_hidden = self.enc_gru(inputs, initial_state = hidden)\n",
        "    return enc_out, enc_hidden\n",
        "  \n",
        "  def hidden_initializer(self):\n",
        "    return tf.zeros(shape = (self.batch_size, self.enc_units))\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXEq1g0OJHZD"
      },
      "source": [
        "#Instantiate and testing the encoder"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUMVG4TsJMp7",
        "outputId": "a9d19cb6-d9d7-4640-89f6-041bc57a5658"
      },
      "source": [
        "encoder = Encoder(units, input_voc_size, batch_size,embedding_dim, name = 'encoder')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1W83lqKbZE"
      },
      "source": [
        "sample_x_batch_train, sample_y_batch_train = next(iter(train_data))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csor4vqrJfR5"
      },
      "source": [
        "hidden_state = encoder.hidden_initializer()"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Dhm8wUKtMx"
      },
      "source": [
        "sample_enc_out, sample_enc_hidden = encoder(sample_x_batch_train, hidden_state)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osTsX5JKK1xX",
        "outputId": "1658293c-7415-425e-fad2-9b3a75c654ae"
      },
      "source": [
        "print(f\"sample_enc_out_shape: {sample_enc_out.shape}\\nsample_enc_hidden_shape: {sample_enc_hidden.shape}\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_enc_out_shape: (64, 14, 1024)\n",
            "sample_enc_hidden_shape: (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jp-8uBeLHSg"
      },
      "source": [
        "#The decoder network without an attention"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVArScicLM1X"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, dec_units, embedding_dim, voc_size, batch_size, name = 'decoder', **kwargs):\n",
        "    super(Decoder, self).__init__(name = name, **kwargs)\n",
        "    self.dec_units = dec_units\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_embedding = tf.keras.layers.Embedding(input_dim = voc_size, output_dim = embedding_dim, name = 'decoder_embd')\n",
        "    self.dec_gru = tf.keras.layers.GRU(units = self.dec_units, kernel_initializer = 'glorot_uniform',\n",
        "                                       return_state = True, return_sequences = True,\n",
        "                                       recurrent_dropout = 0.5, dropout = 0.5,\n",
        "                                       name = 'decoder_gru')\n",
        "    self.fc = tf.keras.layers.Dense(units = voc_size, kernel_initializer = 'glorot_uniform',activation = 'softmax')\n",
        "  \n",
        "  def call(self, inputs, hidden):\n",
        "    inputs = self.dec_embedding(inputs)\n",
        "    dec_out, dec_hidden = self.dec_gru(inputs, initial_state = hidden)\n",
        "    dec_out = tf.reshape(dec_out, shape = (-1, dec_out.shape[2]))\n",
        "    inputs = self.fc(dec_out)\n",
        "    return inputs, dec_hidden"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebeMufO1Q40X"
      },
      "source": [
        "#Instantiate the decoder and testing using the sample batch encoder output "
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8X-3CF8RAZe",
        "outputId": "d6aa1da7-f20d-4b51-ad25-97b14e985792"
      },
      "source": [
        "decoder = Decoder(units, embedding_dim,output_voc_size,batch_size,name = 'decoder')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer decoder_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fijdeMcbRaxu"
      },
      "source": [
        "sample_dec_out, sample_dec_hidden = decoder(tf.random.uniform(shape = (batch_size,1)),sample_enc_hidden)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMIzMauURu1e",
        "outputId": "0639c929-2713-458d-bc93-a07ae9ce04be"
      },
      "source": [
        "print(f\"sample_dec_out_shape: {sample_dec_out.shape}\\nsample_dec_hidden_shape: {sample_dec_hidden.shape}\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_dec_out_shape: (64, 7525)\n",
            "sample_dec_hidden_shape: (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV0pNiT6SH9P"
      },
      "source": [
        "#Dotproduct attention:\n",
        "class DotproductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    query_expanded = tf.expand_dims(query,1)# adding the time dimension\n",
        "    score = query_expanded * values\n",
        "    score = tf.reduce_sum(score, axis = 2)\n",
        "    score = tf.expand_dims(score, axis = 2)\n",
        "    attention_wt = tf.nn.softmax(score, axis = 1)\n",
        "    context = attention_wt * values\n",
        "    context_vector = tf.reduce_sum(context, axis = 1)\n",
        "    return context_vector, attention_wt\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKUHccaglRoh"
      },
      "source": [
        "#Testing the attention \n",
        "attention_layer = DotproductAttention()\n",
        "sample_context_vector, sample_attention_wt = attention_layer(sample_enc_hidden, sample_enc_out)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzjkgapPlupU",
        "outputId": "ef834843-5269-4c42-f390-3022220f79b9"
      },
      "source": [
        "print(f\"sample_context_vector_shape: {sample_context_vector.shape}:\\nsample_attention_wt_shape: {sample_attention_wt.shape}\")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_context_vector_shape: (64, 1024):\n",
            "sample_attention_wt_shape: (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfB16Wl4mJTa"
      },
      "source": [
        "#Bhanadau attention:\n",
        "class BhanadauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, name = 'bhanadau',**kwargs):\n",
        "    super(BhanadauAttention, self).__init__(name = name, **kwargs)\n",
        "    self.W1 = tf.keras.layers.Dense(units = units)\n",
        "    self.W2 = tf.keras.layers.Dense(units = units)\n",
        "    self.V = tf.keras.layers.Dense(units = 1)\n",
        "  \n",
        "  def call(self, query, values):\n",
        "    query_expanded = tf.expand_dims(query, 1) #Add the time dimension for the hidden state\n",
        "    score = self.V(tf.nn.tanh(self.W1(query_expanded) + self.W2(values)))\n",
        "    attention_wt = tf.nn.softmax(score, axis = 1)\n",
        "    context = attention_wt * values\n",
        "    context_vector = tf.reduce_sum(context, axis = 1)\n",
        "    return context_vector, attention_wt"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clD-FIO_xIzl"
      },
      "source": [
        "#Instantiate and testing the bhanadau attention"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MusR45ZxxQtN"
      },
      "source": [
        "bhnadau = BhanadauAttention(10, name = 'bhanadau')"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KvYqoB3xYLX"
      },
      "source": [
        "sample_bhanadau_context_vec, sample_bhanadau_attention_wt = bhnadau(sample_enc_hidden, sample_enc_out)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n2_4MxFxuvk",
        "outputId": "36e42745-0abe-4aba-8d4c-7fea197be102"
      },
      "source": [
        "print(f\"sample_bhanadau_context_vec_shape: {sample_bhanadau_context_vec.shape}\\nsample_nhanadau_attention_wt_shape: {sample_bhanadau_attention_wt.shape}\")"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_bhanadau_context_vec_shape: (64, 1024)\n",
            "sample_nhanadau_attention_wt_shape: (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXQuzwy3yCrH"
      },
      "source": [
        "#Decoder with attention:"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqsfNwUbyHXj"
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self,dec_units, voc_size, batch_size,embedding_dim,attention_layer = None, name = 'dec_with_attention',**kwargs):\n",
        "    super(DecoderWithAttention, self).__init__(name = name, **kwargs)\n",
        "    self.batch_size = batch_size\n",
        "    self.dec_units = dec_units\n",
        "    self.dec_embedding = tf.keras.layers.Embedding(input_dim = voc_size, output_dim = embedding_dim, name = 'dec_embedding')\n",
        "    self.dec_gru = tf.keras.layers.GRU(units = self.dec_units, kernel_initializer = 'glorot_uniform',\n",
        "                                       return_state = True, return_sequences = True,\n",
        "                                       recurrent_dropout = True, dropout = True,\n",
        "                                       name = 'dec_gru')\n",
        "    self.fc = tf.keras.layers.Dense(units = voc_size)\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self,inputs,enc_hidden, enc_out):\n",
        "    inputs = self.dec_embedding(inputs)\n",
        "    attention_wt = None\n",
        "    if self.attention:\n",
        "      context_vector, attention_wt = self.attention(enc_hidden, enc_out)\n",
        "      inputs = tf.concat([tf.expand_dims(context_vector, 1), inputs], axis = -1)\n",
        "      dec_out, dec_hidden_state = self.dec_gru(inputs, initial_state = enc_hidden)\n",
        "      dec_out = tf.reshape(dec_out, shape = (-1, dec_out.shape[2])) \n",
        "      inputs = self.fc(dec_out)\n",
        "      return inputs, dec_hidden_state, attention_wt"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJxUEryf2dXa"
      },
      "source": [
        "#Instantiate and testing the decoder with dotproduct attention"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLUFwZDz2kRm",
        "outputId": "5ec777ab-8ceb-4e7c-9f87-09b0793c9704"
      },
      "source": [
        "decoder_with_attention = DecoderWithAttention(units, output_voc_size,batch_size, embedding_dim,attention_layer= attention_layer, name = 'dec_attn')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dec_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhlzOSF3AnY"
      },
      "source": [
        "sample_dec_out_with_attn, sample_dec_hidden_with_attn,sample_attent_wt = decoder_with_attention(tf.random.uniform(shape = (batch_size,1)), sample_enc_hidden, sample_enc_out)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNclReAd3927",
        "outputId": "bf1d4874-f8ca-4a58-9271-5f5a2c8aebe0"
      },
      "source": [
        "print(f\"sample_dec_hidden_with_attn_shape: {sample_dec_hidden_with_attn.shape}\\nsample_dec_out_with_attn_shape: {sample_dec_out_with_attn.shape}\\nsample_attn_wt-shape: {sample_attent_wt.shape}\")"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_dec_hidden_with_attn_shape: (64, 1024)\n",
            "sample_dec_out_with_attn_shape: (64, 7525)\n",
            "sample_attn_wt-shape: (64, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ChcQtRF9Cnx"
      },
      "source": [
        "#Training loop from scratch"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cjBSrNLFm7Q"
      },
      "source": [
        "#Get the loss function and the optimizer"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mUlOyZdFxxR"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNY7RX9lF_eN"
      },
      "source": [
        "def custom_loss(y_real, y_pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(y_real, 0))\n",
        "  loss_ = loss_object(y_real, y_pred)\n",
        "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
        "  loss_*=mask\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CzYTSTyHdyq"
      },
      "source": [
        "#Testing the custom loss function:\n",
        "loss_object_test = loss_object([1.0,0.8],[[1.0,0.6,0.7,0.2],[0.3,1,0.7,0.5]])"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4fweb4RH9xF"
      },
      "source": [
        "custom_loss_test = custom_loss([1.0,0.8],[[1.0,0.6,0.7,0.2],[0.3,1,0.7,0.5]])"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INAPpk2QIRBf",
        "outputId": "353e5b50-26b7-4ec7-f21c-19f3375ecf1c"
      },
      "source": [
        "print(f\"Loss_object_test gives:{loss_object_test}\\nCustomized loss fn gives: {custom_loss_test:.3f} \")"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss_object_test gives:[1.4509848 1.7451882]\n",
            "Customized loss fn gives: 1.598 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYv-T_rSIqDY"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-3)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImZqgwq2JQou"
      },
      "source": [
        "#The training step fuction using @tf.fuction as decorator to speed excecution"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6cUQh0XJdgV"
      },
      "source": [
        "def get_train_fun():\n",
        "  @tf.function\n",
        "  def train_step(inputs, outputs, enc_hidden, encoder, decoder):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "      enc_out, enc_hidden = encoder(inputs, enc_hidden)\n",
        "      dec_hidden = enc_hidden\n",
        "      dec_inputs = tf.expand_dims([target_lang.word_index['start']] * batch_size, 1)\n",
        "      for t in range(1, outputs.shape[1]):\n",
        "        preds, dec_hidden,attn_wt = decoder(dec_inputs, dec_hidden,enc_out)\n",
        "        loss+=custom_loss(outputs[:,t], preds)\n",
        "        dec_inputs = tf.expand_dims(outputs[:,t],1)\n",
        "    batch_loss = (loss/outputs.shape[1])\n",
        "    trainable_vars = encoder.trainable_variables + decoder.trainable_variables\n",
        "    grads = tape.gradient(loss, trainable_vars)\n",
        "    optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "    return batch_loss\n",
        "  return train_step"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z343jl28d0yE"
      },
      "source": [
        "#Define the validation loss:\n",
        "def custom_validation_loss(inputs, outputs, enc_hidden, encoder, decoder):\n",
        "  loss = 0\n",
        "  enc_out, enc_hidden = encoder(inputs, enc_hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_inputs = tf.expand_dims([target_lang.word_index['start']] * batch_size, 1)\n",
        "  for t in range(1, outputs.shape[1]):\n",
        "    preds,dec_hidden,attn_wt = decoder(dec_inputs,dec_hidden,enc_out)\n",
        "    loss+=custom_loss(outputs[:, t], preds)\n",
        "    dec_inputs = tf.expand_dims(outputs[:, t],1)\n",
        "  loss = (loss / outputs.shape[1])\n",
        "  return loss"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiXEnTsCf66t"
      },
      "source": [
        "#Training the model from scatch:\n",
        "def train_MTN(epochs, attention):\n",
        "  encoder = Encoder(units, input_voc_size,batch_size,embedding_dim,name = 'encoder')\n",
        "  decoder = DecoderWithAttention(units,output_voc_size,batch_size,embedding_dim,attention_layer = attention)\n",
        "  train_step_comp = get_train_fun()\n",
        "  train_loss = []\n",
        "  validation_loss = []\n",
        "  for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    enc_hidden = encoder.hidden_initializer()\n",
        "    total_loss = 0\n",
        "    for (step, (input,output)) in enumerate(train_data.take(step_per_epoch)):\n",
        "      batch_loss = train_step_comp(input,output,enc_hidden,encoder, decoder)\n",
        "      total_loss+=batch_loss\n",
        "      if step % 100 == 0:\n",
        "        print(f\"Epoch: {epoch + 1}: Batch: {step}: Loss: {batch_loss: .4f}\")\n",
        "    \n",
        "    enc_hidden = encoder.hidden_initializer()\n",
        "    total_val_loss = 0\n",
        "    for (step, (input, output)) in enumerate(test_data.take(step_per_epoch_eval)):\n",
        "      val_loss = custom_validation_loss(input,output,enc_hidden,encoder, decoder)\n",
        "      total_val_loss+=val_loss\n",
        "    train_loss.append(total_loss/step_per_epoch)\n",
        "    validation_loss.append(total_val_loss/step_per_epoch_eval)\n",
        "    print(f\"Epoch: {epoch + 1}: Train Loss: {train_loss[-1]:.4f}: Validation Loss: {validation_loss[-1]:.4f}\")\n",
        "    print(f\"Time elapsed is : {time_fmt(time.time()-tic)}\")\n",
        "  return encoder, decoder, train_loss, validation_loss\n",
        "\n"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx5tf8AomNbF"
      },
      "source": [
        "#Training the MTN"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INIMHLt-mQuS",
        "outputId": "8b6d41f6-8daa-4078-d4f0-062ecd9bf9ab"
      },
      "source": [
        "epochs = 15\n",
        "attention = attention_layer\n",
        "encoder, decoder,train_loss, validation_loss = train_MTN(epochs, attention)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer dec_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch: 1: Batch: 0: Loss:  4.1279\n",
            "Epoch: 1: Batch: 100: Loss:  2.0896\n",
            "Epoch: 1: Batch: 200: Loss:  2.1274\n",
            "Epoch: 1: Batch: 300: Loss:  1.7351\n",
            "Epoch: 1: Batch: 400: Loss:  1.8572\n",
            "Epoch: 1: Batch: 500: Loss:  1.5767\n",
            "Epoch: 1: Batch: 600: Loss:  1.6061\n",
            "Epoch: 1: Train Loss: 1.9197: Validation Loss: 1.5464\n",
            "Time elapsed is : 0: 001: 55.00\n",
            "Epoch: 2: Batch: 0: Loss:  1.4572\n",
            "Epoch: 2: Batch: 100: Loss:  1.4176\n",
            "Epoch: 2: Batch: 200: Loss:  1.5282\n",
            "Epoch: 2: Batch: 300: Loss:  1.4668\n",
            "Epoch: 2: Batch: 400: Loss:  1.3292\n",
            "Epoch: 2: Batch: 500: Loss:  1.1903\n",
            "Epoch: 2: Batch: 600: Loss:  1.1544\n",
            "Epoch: 2: Train Loss: 1.3283: Validation Loss: 1.2519\n",
            "Time elapsed is : 0: 001: 42.00\n",
            "Epoch: 3: Batch: 0: Loss:  1.0903\n",
            "Epoch: 3: Batch: 100: Loss:  1.1467\n",
            "Epoch: 3: Batch: 200: Loss:  1.1109\n",
            "Epoch: 3: Batch: 300: Loss:  1.1157\n",
            "Epoch: 3: Batch: 400: Loss:  0.9820\n",
            "Epoch: 3: Batch: 500: Loss:  1.1217\n",
            "Epoch: 3: Batch: 600: Loss:  0.8441\n",
            "Epoch: 3: Train Loss: 1.0349: Validation Loss: 1.1013\n",
            "Time elapsed is : 0: 001: 42.00\n",
            "Epoch: 4: Batch: 0: Loss:  0.8003\n",
            "Epoch: 4: Batch: 100: Loss:  0.9002\n",
            "Epoch: 4: Batch: 200: Loss:  0.7648\n",
            "Epoch: 4: Batch: 300: Loss:  0.8803\n",
            "Epoch: 4: Batch: 400: Loss:  0.7717\n",
            "Epoch: 4: Batch: 500: Loss:  0.8704\n",
            "Epoch: 4: Batch: 600: Loss:  0.9036\n",
            "Epoch: 4: Train Loss: 0.8337: Validation Loss: 1.0228\n",
            "Time elapsed is : 0: 001: 42.00\n",
            "Epoch: 5: Batch: 0: Loss:  0.5556\n",
            "Epoch: 5: Batch: 100: Loss:  0.6797\n",
            "Epoch: 5: Batch: 200: Loss:  0.6524\n",
            "Epoch: 5: Batch: 300: Loss:  0.6007\n",
            "Epoch: 5: Batch: 400: Loss:  0.7341\n",
            "Epoch: 5: Batch: 500: Loss:  0.6857\n",
            "Epoch: 5: Batch: 600: Loss:  0.7204\n",
            "Epoch: 5: Train Loss: 0.6855: Validation Loss: 0.9769\n",
            "Time elapsed is : 0: 001: 42.00\n",
            "Epoch: 6: Batch: 0: Loss:  0.5220\n",
            "Epoch: 6: Batch: 100: Loss:  0.5834\n",
            "Epoch: 6: Batch: 200: Loss:  0.4932\n",
            "Epoch: 6: Batch: 300: Loss:  0.5580\n",
            "Epoch: 6: Batch: 400: Loss:  0.4956\n",
            "Epoch: 6: Batch: 500: Loss:  0.5036\n",
            "Epoch: 6: Batch: 600: Loss:  0.6576\n",
            "Epoch: 6: Train Loss: 0.5790: Validation Loss: 0.9595\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 7: Batch: 0: Loss:  0.4775\n",
            "Epoch: 7: Batch: 100: Loss:  0.4588\n",
            "Epoch: 7: Batch: 200: Loss:  0.4732\n",
            "Epoch: 7: Batch: 300: Loss:  0.4437\n",
            "Epoch: 7: Batch: 400: Loss:  0.4364\n",
            "Epoch: 7: Batch: 500: Loss:  0.5736\n",
            "Epoch: 7: Batch: 600: Loss:  0.5818\n",
            "Epoch: 7: Train Loss: 0.5074: Validation Loss: 0.9635\n",
            "Time elapsed is : 0: 001: 42.00\n",
            "Epoch: 8: Batch: 0: Loss:  0.4438\n",
            "Epoch: 8: Batch: 100: Loss:  0.3916\n",
            "Epoch: 8: Batch: 200: Loss:  0.4708\n",
            "Epoch: 8: Batch: 300: Loss:  0.5004\n",
            "Epoch: 8: Batch: 400: Loss:  0.3979\n",
            "Epoch: 8: Batch: 500: Loss:  0.5702\n",
            "Epoch: 8: Batch: 600: Loss:  0.5410\n",
            "Epoch: 8: Train Loss: 0.4536: Validation Loss: 0.9674\n",
            "Time elapsed is : 0: 001: 42.00\n",
            "Epoch: 9: Batch: 0: Loss:  0.1899\n",
            "Epoch: 9: Batch: 100: Loss:  0.3699\n",
            "Epoch: 9: Batch: 200: Loss:  0.4354\n",
            "Epoch: 9: Batch: 300: Loss:  0.4499\n",
            "Epoch: 9: Batch: 400: Loss:  0.5677\n",
            "Epoch: 9: Batch: 500: Loss:  0.4811\n",
            "Epoch: 9: Batch: 600: Loss:  0.4041\n",
            "Epoch: 9: Train Loss: 0.4148: Validation Loss: 0.9712\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 10: Batch: 0: Loss:  0.3699\n",
            "Epoch: 10: Batch: 100: Loss:  0.3142\n",
            "Epoch: 10: Batch: 200: Loss:  0.3113\n",
            "Epoch: 10: Batch: 300: Loss:  0.3830\n",
            "Epoch: 10: Batch: 400: Loss:  0.4760\n",
            "Epoch: 10: Batch: 500: Loss:  0.4999\n",
            "Epoch: 10: Batch: 600: Loss:  0.3581\n",
            "Epoch: 10: Train Loss: 0.3875: Validation Loss: 0.9797\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 11: Batch: 0: Loss:  0.2907\n",
            "Epoch: 11: Batch: 100: Loss:  0.2872\n",
            "Epoch: 11: Batch: 200: Loss:  0.4125\n",
            "Epoch: 11: Batch: 300: Loss:  0.4726\n",
            "Epoch: 11: Batch: 400: Loss:  0.3150\n",
            "Epoch: 11: Batch: 500: Loss:  0.3170\n",
            "Epoch: 11: Batch: 600: Loss:  0.5655\n",
            "Epoch: 11: Train Loss: 0.3679: Validation Loss: 0.9766\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 12: Batch: 0: Loss:  0.2662\n",
            "Epoch: 12: Batch: 100: Loss:  0.2909\n",
            "Epoch: 12: Batch: 200: Loss:  0.2517\n",
            "Epoch: 12: Batch: 300: Loss:  0.3711\n",
            "Epoch: 12: Batch: 400: Loss:  0.3500\n",
            "Epoch: 12: Batch: 500: Loss:  0.3018\n",
            "Epoch: 12: Batch: 600: Loss:  0.3018\n",
            "Epoch: 12: Train Loss: 0.3530: Validation Loss: 0.9829\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 13: Batch: 0: Loss:  0.2054\n",
            "Epoch: 13: Batch: 100: Loss:  0.4076\n",
            "Epoch: 13: Batch: 200: Loss:  0.2132\n",
            "Epoch: 13: Batch: 300: Loss:  0.3239\n",
            "Epoch: 13: Batch: 400: Loss:  0.3050\n",
            "Epoch: 13: Batch: 500: Loss:  0.2762\n",
            "Epoch: 13: Batch: 600: Loss:  0.4524\n",
            "Epoch: 13: Train Loss: 0.3424: Validation Loss: 0.9887\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 14: Batch: 0: Loss:  0.2860\n",
            "Epoch: 14: Batch: 100: Loss:  0.3152\n",
            "Epoch: 14: Batch: 200: Loss:  0.2803\n",
            "Epoch: 14: Batch: 300: Loss:  0.3048\n",
            "Epoch: 14: Batch: 400: Loss:  0.3764\n",
            "Epoch: 14: Batch: 500: Loss:  0.3058\n",
            "Epoch: 14: Batch: 600: Loss:  0.3661\n",
            "Epoch: 14: Train Loss: 0.3339: Validation Loss: 0.9896\n",
            "Time elapsed is : 0: 001: 41.00\n",
            "Epoch: 15: Batch: 0: Loss:  0.2888\n",
            "Epoch: 15: Batch: 100: Loss:  0.2179\n",
            "Epoch: 15: Batch: 200: Loss:  0.2906\n",
            "Epoch: 15: Batch: 300: Loss:  0.2287\n",
            "Epoch: 15: Batch: 400: Loss:  0.2547\n",
            "Epoch: 15: Batch: 500: Loss:  0.3514\n",
            "Epoch: 15: Batch: 600: Loss:  0.4102\n",
            "Epoch: 15: Train Loss: 0.3256: Validation Loss: 0.9920\n",
            "Time elapsed is : 0: 001: 41.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xszAqzB0uvEG",
        "outputId": "8b646018-e448-423d-b4e3-354b4b87cd68"
      },
      "source": [
        "epochs = 15\n",
        "attention = bhnadau\n",
        "encoder, decoder,train_loss, validation_loss = train_MTN(epochs, attention)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer dec_gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch: 1: Batch: 0: Loss:  3.9051\n",
            "Epoch: 1: Batch: 100: Loss:  2.3026\n",
            "Epoch: 1: Batch: 200: Loss:  1.9640\n",
            "Epoch: 1: Batch: 300: Loss:  1.6806\n",
            "Epoch: 1: Batch: 400: Loss:  1.5599\n",
            "Epoch: 1: Batch: 500: Loss:  1.5685\n",
            "Epoch: 1: Batch: 600: Loss:  1.5704\n",
            "Epoch: 1: Train Loss: 1.8707: Validation Loss: 1.4882\n",
            "Time elapsed is : 0: 001: 56.00\n",
            "Epoch: 2: Batch: 0: Loss:  1.2919\n",
            "Epoch: 2: Batch: 100: Loss:  1.3495\n",
            "Epoch: 2: Batch: 200: Loss:  1.0954\n",
            "Epoch: 2: Batch: 300: Loss:  1.3205\n",
            "Epoch: 2: Batch: 400: Loss:  1.2194\n",
            "Epoch: 2: Batch: 500: Loss:  1.1985\n",
            "Epoch: 2: Batch: 600: Loss:  0.9686\n",
            "Epoch: 2: Train Loss: 1.2674: Validation Loss: 1.1746\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 3: Batch: 0: Loss:  0.9395\n",
            "Epoch: 3: Batch: 100: Loss:  1.0114\n",
            "Epoch: 3: Batch: 200: Loss:  1.0499\n",
            "Epoch: 3: Batch: 300: Loss:  1.0728\n",
            "Epoch: 3: Batch: 400: Loss:  0.8695\n",
            "Epoch: 3: Batch: 500: Loss:  0.8148\n",
            "Epoch: 3: Batch: 600: Loss:  0.8728\n",
            "Epoch: 3: Train Loss: 0.9615: Validation Loss: 1.0284\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 4: Batch: 0: Loss:  0.8583\n",
            "Epoch: 4: Batch: 100: Loss:  0.7522\n",
            "Epoch: 4: Batch: 200: Loss:  0.7827\n",
            "Epoch: 4: Batch: 300: Loss:  0.6126\n",
            "Epoch: 4: Batch: 400: Loss:  0.7088\n",
            "Epoch: 4: Batch: 500: Loss:  0.6915\n",
            "Epoch: 4: Batch: 600: Loss:  0.7726\n",
            "Epoch: 4: Train Loss: 0.7612: Validation Loss: 0.9538\n",
            "Time elapsed is : 0: 001: 44.00\n",
            "Epoch: 5: Batch: 0: Loss:  0.5302\n",
            "Epoch: 5: Batch: 100: Loss:  0.6112\n",
            "Epoch: 5: Batch: 200: Loss:  0.5267\n",
            "Epoch: 5: Batch: 300: Loss:  0.7079\n",
            "Epoch: 5: Batch: 400: Loss:  0.7415\n",
            "Epoch: 5: Batch: 500: Loss:  0.7205\n",
            "Epoch: 5: Batch: 600: Loss:  0.6336\n",
            "Epoch: 5: Train Loss: 0.6166: Validation Loss: 0.9213\n",
            "Time elapsed is : 0: 001: 44.00\n",
            "Epoch: 6: Batch: 0: Loss:  0.5222\n",
            "Epoch: 6: Batch: 100: Loss:  0.4644\n",
            "Epoch: 6: Batch: 200: Loss:  0.5323\n",
            "Epoch: 6: Batch: 300: Loss:  0.5265\n",
            "Epoch: 6: Batch: 400: Loss:  0.4760\n",
            "Epoch: 6: Batch: 500: Loss:  0.5214\n",
            "Epoch: 6: Batch: 600: Loss:  0.5638\n",
            "Epoch: 6: Train Loss: 0.5133: Validation Loss: 0.9104\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 7: Batch: 0: Loss:  0.4748\n",
            "Epoch: 7: Batch: 100: Loss:  0.4315\n",
            "Epoch: 7: Batch: 200: Loss:  0.3135\n",
            "Epoch: 7: Batch: 300: Loss:  0.5060\n",
            "Epoch: 7: Batch: 400: Loss:  0.4364\n",
            "Epoch: 7: Batch: 500: Loss:  0.5796\n",
            "Epoch: 7: Batch: 600: Loss:  0.5790\n",
            "Epoch: 7: Train Loss: 0.4456: Validation Loss: 0.9128\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 8: Batch: 0: Loss:  0.3881\n",
            "Epoch: 8: Batch: 100: Loss:  0.4115\n",
            "Epoch: 8: Batch: 200: Loss:  0.3191\n",
            "Epoch: 8: Batch: 300: Loss:  0.4243\n",
            "Epoch: 8: Batch: 400: Loss:  0.3545\n",
            "Epoch: 8: Batch: 500: Loss:  0.3788\n",
            "Epoch: 8: Batch: 600: Loss:  0.4937\n",
            "Epoch: 8: Train Loss: 0.4019: Validation Loss: 0.9253\n",
            "Time elapsed is : 0: 001: 44.00\n",
            "Epoch: 9: Batch: 0: Loss:  0.2464\n",
            "Epoch: 9: Batch: 100: Loss:  0.3898\n",
            "Epoch: 9: Batch: 200: Loss:  0.3272\n",
            "Epoch: 9: Batch: 300: Loss:  0.4148\n",
            "Epoch: 9: Batch: 400: Loss:  0.3038\n",
            "Epoch: 9: Batch: 500: Loss:  0.4275\n",
            "Epoch: 9: Batch: 600: Loss:  0.4183\n",
            "Epoch: 9: Train Loss: 0.3732: Validation Loss: 0.9297\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 10: Batch: 0: Loss:  0.2848\n",
            "Epoch: 10: Batch: 100: Loss:  0.3494\n",
            "Epoch: 10: Batch: 200: Loss:  0.2965\n",
            "Epoch: 10: Batch: 300: Loss:  0.3535\n",
            "Epoch: 10: Batch: 400: Loss:  0.4575\n",
            "Epoch: 10: Batch: 500: Loss:  0.3676\n",
            "Epoch: 10: Batch: 600: Loss:  0.4976\n",
            "Epoch: 10: Train Loss: 0.3527: Validation Loss: 0.9363\n",
            "Time elapsed is : 0: 001: 44.00\n",
            "Epoch: 11: Batch: 0: Loss:  0.3375\n",
            "Epoch: 11: Batch: 100: Loss:  0.3503\n",
            "Epoch: 11: Batch: 200: Loss:  0.3217\n",
            "Epoch: 11: Batch: 300: Loss:  0.2548\n",
            "Epoch: 11: Batch: 400: Loss:  0.2849\n",
            "Epoch: 11: Batch: 500: Loss:  0.3721\n",
            "Epoch: 11: Batch: 600: Loss:  0.2897\n",
            "Epoch: 11: Train Loss: 0.3347: Validation Loss: 0.9379\n",
            "Time elapsed is : 0: 001: 44.00\n",
            "Epoch: 12: Batch: 0: Loss:  0.2741\n",
            "Epoch: 12: Batch: 100: Loss:  0.2648\n",
            "Epoch: 12: Batch: 200: Loss:  0.2960\n",
            "Epoch: 12: Batch: 300: Loss:  0.4360\n",
            "Epoch: 12: Batch: 400: Loss:  0.3550\n",
            "Epoch: 12: Batch: 500: Loss:  0.3452\n",
            "Epoch: 12: Batch: 600: Loss:  0.4022\n",
            "Epoch: 12: Train Loss: 0.3238: Validation Loss: 0.9385\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 13: Batch: 0: Loss:  0.3760\n",
            "Epoch: 13: Batch: 100: Loss:  0.3463\n",
            "Epoch: 13: Batch: 200: Loss:  0.2365\n",
            "Epoch: 13: Batch: 300: Loss:  0.2221\n",
            "Epoch: 13: Batch: 400: Loss:  0.3405\n",
            "Epoch: 13: Batch: 500: Loss:  0.2728\n",
            "Epoch: 13: Batch: 600: Loss:  0.4504\n",
            "Epoch: 13: Train Loss: 0.3136: Validation Loss: 0.9382\n",
            "Time elapsed is : 0: 001: 43.00\n",
            "Epoch: 14: Batch: 0: Loss:  0.2972\n",
            "Epoch: 14: Batch: 100: Loss:  0.3905\n",
            "Epoch: 14: Batch: 200: Loss:  0.2831\n",
            "Epoch: 14: Batch: 300: Loss:  0.3325\n",
            "Epoch: 14: Batch: 400: Loss:  0.3641\n",
            "Epoch: 14: Batch: 500: Loss:  0.3163\n",
            "Epoch: 14: Batch: 600: Loss:  0.3312\n",
            "Epoch: 14: Train Loss: 0.3058: Validation Loss: 0.9396\n",
            "Time elapsed is : 0: 001: 44.00\n",
            "Epoch: 15: Batch: 0: Loss:  0.2705\n",
            "Epoch: 15: Batch: 100: Loss:  0.3161\n",
            "Epoch: 15: Batch: 200: Loss:  0.1901\n",
            "Epoch: 15: Batch: 300: Loss:  0.2745\n",
            "Epoch: 15: Batch: 400: Loss:  0.3489\n",
            "Epoch: 15: Batch: 500: Loss:  0.2748\n",
            "Epoch: 15: Batch: 600: Loss:  0.3921\n",
            "Epoch: 15: Train Loss: 0.2987: Validation Loss: 0.9436\n",
            "Time elapsed is : 0: 001: 43.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrhUuj7NBz9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}